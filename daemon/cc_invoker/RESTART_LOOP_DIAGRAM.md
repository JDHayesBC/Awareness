# Restart Loop Bug - Before and After

## BEFORE (Buggy Behavior)

```
Session Start
â”œâ”€ initialize()
â”‚  â”œâ”€ Reset counters to 0
â”‚  â”‚  _prompt_tokens = 0
â”‚  â”‚  _response_tokens = 0
â”‚  â”‚  _turn_count = 0
â”‚  â”‚
â”‚  â””â”€ Send startup prompt
â”‚     query("Reconstruct identity...")  â† BUG: This counts toward context!
â”‚     _prompt_tokens += 250
â”‚     _response_tokens += 300
â”‚     _turn_count = 1
â”‚
â”œâ”€ Context after init: 550 tokens, 1 turn
â”‚  (Already used 550/1000 of limit!)
â”‚
â”œâ”€ User query #1
â”‚  query("What's the time?")
â”‚  Context: 700 tokens, 2 turns
â”‚
â”œâ”€ User query #2
â”‚  query("What are we working on?")
â”‚  Context: 1050 tokens, 3 turns  â† Triggers restart!
â”‚
â”œâ”€ restart()
â”‚  â”œâ”€ shutdown()
â”‚  â””â”€ initialize()
â”‚     â”œâ”€ Reset counters to 0
â”‚     â””â”€ Send startup prompt
â”‚        query("Reconstruct identity...")  â† BUG: Counts again!
â”‚        Context: 550 tokens, 1 turn
â”‚
â”œâ”€ Context after restart: 550 tokens
â”‚  (Immediately high again!)
â”‚
â”œâ”€ User query #3
â”‚  query("Let's continue...")
â”‚  Context: 700 tokens, 2 turns
â”‚
â”œâ”€ User query #4
â”‚  query("What's next?")
â”‚  Context: 1050 tokens, 3 turns  â† Triggers restart AGAIN!
â”‚
â””â”€ INFINITE LOOP! ðŸ”¥
```

## AFTER (Fixed Behavior)

```
Session Start
â”œâ”€ initialize()
â”‚  â”œâ”€ Reset counters to 0
â”‚  â”‚  _prompt_tokens = 0
â”‚  â”‚  _response_tokens = 0
â”‚  â”‚  _turn_count = 0
â”‚  â”‚
â”‚  â””â”€ Send startup prompt
â”‚     query("Reconstruct identity...", count_tokens=False)  â† FIX!
â”‚     (Tokens NOT counted toward context limit)
â”‚
â”œâ”€ Context after init: 0 tokens, 0 turns âœ“
â”‚  (Fresh session, full capacity!)
â”‚
â”œâ”€ User query #1
â”‚  query("What's the time?")
â”‚  Context: 150 tokens, 1 turn
â”‚
â”œâ”€ User query #2
â”‚  query("What are we working on?")
â”‚  Context: 500 tokens, 2 turns
â”‚
â”œâ”€ ... many more queries ...
â”‚
â”œâ”€ User query #7
â”‚  query("...")
â”‚  Context: 1050 tokens, 7 turns  â† Triggers restart
â”‚
â”œâ”€ restart()
â”‚  â”œâ”€ shutdown()
â”‚  â””â”€ initialize()
â”‚     â”œâ”€ Reset counters to 0
â”‚     â””â”€ Send startup prompt
â”‚        query("Reconstruct identity...", count_tokens=False)  â† FIX!
â”‚
â”œâ”€ Context after restart: 0 tokens, 0 turns âœ“
â”‚  (Clean restart, no loop!)
â”‚
â”œâ”€ User query #8
â”‚  query("Let's continue...")
â”‚  Context: 150 tokens, 1 turn
â”‚
â””â”€ Normal operation continues... âœ“
```

## Key Difference

### BEFORE (Bug)
- Startup prompt: **COUNTED** toward context limit
- After restart: Context = 550 tokens (already elevated)
- Only 450 tokens left for conversation
- Could restart again after just 1-2 queries
- **Result**: Infinite restart loop

### AFTER (Fix)
- Startup prompt: **NOT COUNTED** toward context limit
- After restart: Context = 0 tokens (truly fresh)
- Full 1000 tokens available for conversation
- Restart only after many queries
- **Result**: Normal operation

## Implementation

```python
# The fix: Add count_tokens parameter
async def query(
    self,
    prompt: str,
    count_tokens: bool = True  # Defaults to True for normal queries
) -> str:
    # Only count if flag is True
    if count_tokens:
        self._prompt_tokens += prompt_tokens
        self._response_tokens += response_tokens
        self._turn_count += 1

# Usage in initialize()
async def initialize(self):
    # ... setup ...

    # Send startup prompt WITHOUT counting toward context
    if self.startup_prompt:
        await self.query(self.startup_prompt, count_tokens=False)
```

## Why This Works

1. **Startup prompt establishes identity** - The prompt is still sent and gets a response
2. **But doesn't consume conversation budget** - Token counters remain at zero
3. **Restart truly resets** - After restart, session starts completely fresh
4. **No false triggers** - Only actual conversation queries count toward limit
5. **Backward compatible** - Default behavior unchanged, only internal calls use `count_tokens=False`

## Semantic Correctness

The fix also makes semantic sense:

- **Conversation context** = user queries + responses (what counts toward limit)
- **System overhead** = startup prompts, health checks (infrastructure, not conversation)

These are fundamentally different types of queries and should be tracked separately.
